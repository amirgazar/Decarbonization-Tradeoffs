#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=2:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/2 Dispatch Curve.R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve_", pathway, "_sim_", i, ".sh"))
writeLines(bash_script, bash_file)
}
}
#---- Simple Code
# Load bash script
bash_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/BASH_File.sh"
# Upload the Bash script to the remote server
ssh::scp_upload(session, bash_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes")
# Load R script
R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R"
ssh::scp_upload(session, R_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/")
# Define the command to submit the SLURM job + Change directory
commands <- 'cd "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/" && sbatch -A epadecarb BASH_File.sh'
# Execute the command
ssh::ssh_exec_wait(session, command = commands)
bash_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/BASH_File.sh"
# Upload the Bash script to the remote server
ssh::scp_upload(session, bash_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes")
# Load R script
R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R"
ssh::scp_upload(session, R_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/")
# Define the command to submit the SLURM job + Change directory
commands <- 'cd "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/" && sbatch -A epadecarb BASH_File.sh'
# Execute the command
ssh::ssh_exec_wait(session, command = commands)
bash_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/BASH_File.sh"
# Upload the Bash script to the remote server
ssh::scp_upload(session, bash_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes")
# Load R script
R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R"
ssh::scp_upload(session, R_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/")
# Define the command to submit the SLURM job + Change directory
commands <- 'cd "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/" && sbatch -A epadecarb BASH_File.sh'
# Execute the command
ssh::ssh_exec_wait(session, command = commands)
pathways <- pathways[1:3]
n_simulations <- 1
sim_start <- 1
sim_idx <- sim_start:(n_simulations + sim_start)
sim_idx
sim_start <- 2
sim_idx <- sim_start:(n_simulations + sim_start)
sim_idx
n_simulations <- 10
sim_start <- 1
sim_idx <- sim_start:(n_simulations + sim_start)
sim_idx
# Loop over each simulation and pathway combination
for(sim in sim_idx) {
for(pathway in pathways) {
cat("Running simulation:", sim, "\n")
cat("Processing pathway:", pathway, "\n")
# Execute the dispatch curve for the current simulation and pathway
dispatch_curve_results <- dispatch_curve(sim, pathway)
dispatch_curve_results <- dispatch_curve_results[1:10, ] # Test the code
# Get fossil fuels hourly adjustments based on the dispatch results
fossil_fuels_hourly_results <- dispatch_curve_adjustments(dispatch_curve_results)
# Calibrate the final hourly results using the dispatch results and the adjustments
final_hourly_results <- dispatch_curve_calibrations(dispatch_curve_results, fossil_fuels_hourly_results)
# Tag results with simulation and pathway information for later identification
final_hourly_results$Simulation <- sim
final_hourly_results$Pathway <- pathway
fossil_fuels_hourly_results$Simulation <- sim
fossil_fuels_hourly_results$Pathway <- pathway
## ----- 4. Save results to CSV files ------
# Get the current timestamp
timestamp <- format(Sys.time(), "%Y_%m_%d_%H%M")
# Define the file paths with simulation and pathway included in the file name
hourly_results_path <- sprintf("/projects/epadecarb/2 Generation Expansion Model/4 Results/1 Stepwise/Hourly_Results_sim%d_path%s_time%s.csv",
sim, pathway, timestamp)
facility_level_results_path <- sprintf("/projects/epadecarb/2 Generation Expansion Model/4 Results/1 Stepwise/Facility_Level_Results_sim%d_path%s_time%s.csv",
sim, pathway, timestamp)
# Save the results to CSV files
write.csv(final_hourly_results, hourly_results_path, row.names = FALSE)
write.csv(fossil_fuels_hourly_results, facility_level_results_path, row.names = FALSE)
# Remove objects from memory to free up space for the next simulation/pathway iteration
rm(dispatch_curve_results, fossil_fuels_hourly_results, final_hourly_results)
gc()  # Force garbage collection to reclaim memory
}
}
## ----- 3. Run the simulations ------
# Set all pathways from Hourly_Installed_Capacity$Pathway
pathways <- unique(Hourly_Installed_Capacity$Pathway)
n_simulations <- 10
sim_start <- 1
sim_idx <- sim_start:(n_simulations + sim_start)
sim_idx
sim_idx <- sim_start:(n_simulations + sim_start - 1)
sim_idx
sim_start <- 11
sim_idx <- sim_start:(n_simulations + sim_start - 1)
sim_idx
bash_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/BASH_File.sh"
# Upload the Bash script to the remote server
ssh::scp_upload(session, bash_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes")
# Load R script
R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R"
ssh::scp_upload(session, R_file, to = "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/")
# Define the command to submit the SLURM job + Change directory
commands <- 'cd "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/" && sbatch -A epadecarb BASH_File.sh'
# Execute the command
ssh::ssh_exec_wait(session, command = commands)
# Cancel JOB
ssh::ssh_exec_wait(session, command = "scancel 3012136")
80*10/2
400/30
80*10
80*10*30/60
400/2
8*10*15
1200/60
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 20  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve_", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=2:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/Dispatch_Curve_", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve_", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
sim_start <- 20
sim_idx <- sim_start:(n_simulations + sim_start - 1)
sim_idx
sim_start <- 10
sim_idx <- sim_start:(n_simulations + sim_start - 1)
sim_idx
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 20  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve_", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=2:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/Dispatch_Curve_", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve_", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 20  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve_", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=24:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/Dispatch_Curve_", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve_", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 20  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=24:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/Dispatch_Curve", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
pathways <- unique(Hourly_Installed_Capacity$Pathway)
n_simulations <- 10
sim_start <- 10
sim_idx <- sim_start:(n_simulations + sim_start - 1)
sim_idx
#---- Batch processing
# Uploading Rcode
Rcode_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Path to local folder containing R files
remote_folder <- "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/" # Remote folder path
r_files <- list.files(Rcode_folder, pattern = "\\.R$", full.names = TRUE)
for (r_file in r_files) {
ssh::scp_upload(session, r_file, to = remote_folder)
}
# Load bash script
# Get list of Bash files in the folder
bash_files <- list.files(Rcode_folder, pattern = "\\.sh$", full.names = TRUE)
# Loop through each Bash file
for (bash_file in bash_files) {
# Get the base name of the Bash file
bash_file_name <- basename(bash_file)
ssh::scp_upload(session, bash_file, to = remote_folder)
# Execute the uploaded Bash script on the remote server
commands <- paste0("cd ", remote_folder, " && sbatch -A epadecarb ", bash_file_name)
ssh::ssh_exec_wait(session, command = commands)
}
commands
# Execute the uploaded Bash script on the remote server
commands <- paste0("'cd ", remote_folder, " && sbatch -A epadecarb ", bash_file_name, "'")
commands
bash_files
# Execute the uploaded Bash script on the remote server
commands <- paste0("'cd ", remote_folder, " && sbatch -A epadecarb ", bash_file_name, "'")
commands
# Define the command to submit the SLURM job + Change directory
commands <- 'cd "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/" && sbatch -A epadecarb BASH_File.sh'
# Execute the uploaded Bash script on the remote server
commands <- paste0('cd "', remote_folder, '" && sbatch -A epadecarb ', bash_file_name)
commands
# Load bash script
# Get list of Bash files in the folder
bash_files <- list.files(Rcode_folder, pattern = "\\.sh$", full.names = TRUE)
# Loop through each Bash file
for (bash_file in bash_files) {
# Get the base name of the Bash file
bash_file_name <- basename(bash_file)
ssh::scp_upload(session, bash_file, to = remote_folder)
# Execute the uploaded Bash script on the remote server
commands <- paste0('cd "', remote_folder, '" && sbatch -A epadecarb ', bash_file_name)
ssh::ssh_exec_wait(session, command = commands)
}
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 20  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=24:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/Dispatch_Curve", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
# Uploading Rcode
Rcode_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Path to local folder containing R files
remote_folder <- "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/" # Remote folder path
r_files <- list.files(Rcode_folder, pattern = "\\.R$", full.names = TRUE)
for (r_file in r_files) {
ssh::scp_upload(session, r_file, to = remote_folder)
}
# Load bash script
# Get list of Bash files in the folder
bash_files <- list.files(Rcode_folder, pattern = "\\.sh$", full.names = TRUE)
bash_files
# Loop through each Bash file
for (bash_file in bash_files) {
# Get the base name of the Bash file
bash_file_name <- basename(bash_file)
ssh::scp_upload(session, bash_file, to = remote_folder)
# Execute the uploaded Bash script on the remote server
commands <- paste0('cd "', remote_folder, '" && sbatch -A epadecarb ', bash_file_name)
ssh::ssh_exec_wait(session, command = commands)
}
i
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 20  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(210, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=24:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/Dispatch_Curve", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 200  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=24:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/Dispatch_Curve", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
Rcode_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Path to local folder containing R files
remote_folder <- "/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/" # Remote folder path
r_files <- list.files(Rcode_folder, pattern = "\\.R$", full.names = TRUE)
for (r_file in r_files) {
ssh::scp_upload(session, r_file, to = remote_folder)
}
# Load bash script
# Get list of Bash files in the folder
bash_files <- list.files(Rcode_folder, pattern = "\\.sh$", full.names = TRUE)
# Loop through each Bash file
for (bash_file in bash_files) {
# Get the base name of the Bash file
bash_file_name <- basename(bash_file)
ssh::scp_upload(session, bash_file, to = remote_folder)
# Execute the uploaded Bash script on the remote server
commands <- paste0('cd "', remote_folder, '" && sbatch -A epadecarb ', bash_file_name)
ssh::ssh_exec_wait(session, command = commands)
}
# Load necessary library
library(data.table)
# Define paths and parameters
original_R_file <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 ARC Codes/2 Dispatch Curve.R" # Full path to the original R file
output_folder <- "/Users/amirgazar/Documents/GitHub/Decarbonization-Tradeoffs/2 Generation Expansion Model/5 Dispatch Curve/2 Advanced Research Computing/1 RCodes to submit/1 Comp Days" # Full path to the folder where new files will be saved
n_sim <- 200  # Number of iterations
# Loop to generate R and Bash files for each pathway and iteration,
# with 'i' taking values 10, 20, ..., 200.
for (i in seq(10, n_sim * 10, by = 10)) {
# ----- Modify R File -----
# Read the original R file
content <- readLines(original_R_file)
# Modify the variable for iteration and pathway_id
content <- gsub(
pattern = paste0("sim_start <- .*"),
replacement = paste0("sim_start <- ", i),
x = content
)
# Save the modified R file with pathway-specific and iteration-specific naming
new_r_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".R"))
writeLines(content, new_r_file)
# ----- Generate Bash Script -----
# Define bash script content
bash_script <- paste0("#!/bin/bash
#SBATCH --account=epadecarb
#SBATCH --partition=normal_q
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=80
#SBATCH --cpus-per-task=1  # Reduce the number of cores to avoid OOM
#SBATCH --time=24:00:00    # Set a more appropriate time limit
module load containers/singularity
singularity exec --bind /projects /projects/arcsingularity/ood-rstudio141717-basic_4.1.0.sif Rscript \"/projects/epadecarb/2 Generation Expansion Model/2 R Codes/1 Comp Days/Dispatch_Curve", "_iteration_", i, ".R\"
module reset")
# Save the bash script with pathway-specific and iteration-specific naming
bash_file <- file.path(output_folder, paste0("Dispatch_Curve", "_iteration_", i, ".sh"))
writeLines(bash_script, bash_file)
}
# Disconnect
#-----
ssh::ssh_disconnect(session)
